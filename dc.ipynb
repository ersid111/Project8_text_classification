{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e899aec1-54e0-47d2-ab0f-b0d64dad37e8",
   "metadata": {},
   "source": [
    "Project: \n",
    "    \n",
    "    \n",
    "    1. problem Statement: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6adb9ada-4e2c-43d2-b420-80cfce774790",
   "metadata": {},
   "source": [
    "Labeled Data  : \n",
    "Unlabelled Data : \n",
    "    \n",
    "    DBMS \n",
    "    \n",
    "    SQL \n",
    "    NoSQL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e790d3b-0799-4f50-942b-b8ec4e2f3840",
   "metadata": {},
   "source": [
    "# 1. Problem Statement "
   ]
  },
  {
   "cell_type": "raw",
   "id": "22f5bf55-a71b-43d4-817a-956b46e69faf",
   "metadata": {},
   "source": [
    "Document classification for insurance domain : \n",
    "    Data Gathring : \n",
    "    insurance domain: Received data in pdf format \n",
    "    \n",
    "    Used OCR to convert into text [python script , regexp, file operation ] \n",
    "    \n",
    "    Data Preprocessing [missing value, pattern matching ]\n",
    "    \n",
    "    \n",
    "    classes : 5 - 15\n",
    "    \n",
    "    \n",
    "    Achieved: we have achieved around 80% automation using this process "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9dadfa04-ffbd-4077-a000-b18442cab1bb",
   "metadata": {},
   "source": [
    "Classes\n",
    "\n",
    "news domain : 5 -6 \n",
    "education engg : 8 - 10\n",
    "healthcare domain : 15 - 20 \n",
    "\n",
    "Music: 10-15\n",
    "\n",
    "sports : 5- 6 \n",
    "\n",
    "\n",
    "\n",
    "POC  >> Proof of concept \n",
    "\n",
    "Data : \n",
    "    50k - 1.5 lakhs \n",
    "    \n",
    "final project : 1 cr to 1.5 cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee3f9b4-9e83-4988-be52-d51b6a8c3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b5fb2a-68e9-4e6f-9421-dd3aee883fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"text\\bbc\"\n",
    "\n",
    "b_text_files = glob.glob('text\\\\bbc\\\\business\\\\*.txt')\n",
    "# b_text_files\n",
    "files = os.listdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b82d99-36e3-43cf-88b0-eb1f7a3e130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artilce_list=[]\n",
    "for file in files:\n",
    "    \n",
    "    text_files = glob.glob(f\"{path}\\{file}\\\\*.txt\")\n",
    "    # print(text_files)\n",
    "    for text_file in text_files:\n",
    "        with open(text_file,'r') as f:\n",
    "            text = f.read()\n",
    "            artilce_list.append(text)\n",
    "len(artilce_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84321bac-0e74-492f-abf9-285f0b821b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL\\'s existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\\n\\nTime Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\\n\\nTimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann\\'s purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artilce_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c144371-b06a-497a-a86c-a1c2f6860500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"text\\bbc\"\n",
    "\n",
    "# b_text_files = glob.glob('text\\\\bbc\\\\business\\\\*.txt')\n",
    "# # b_text_files\n",
    "files = os.listdir(path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ce8508-ebbe-4aab-a6ba-80facb8b39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_class = path + '\\\\business'\n",
    "business_class_text_files = glob.glob(f\"{business_class}\\\\*.txt\")\n",
    "\n",
    "entertainment_class = path + '\\\\entertainment'\n",
    "entertainment_class_text_files = glob.glob(f\"{entertainment_class}\\\\*.txt\")\n",
    "                                           \n",
    "politics_class = path + '\\\\politics'\n",
    "politics_class_text_files =  glob.glob(f\"{politics_class}\\\\*.txt\")\n",
    "\n",
    "sport_class = path + '\\\\sport'\n",
    "sport_class_text_files = glob.glob(f\"{sport_class}\\\\*.txt\")\n",
    "\n",
    "tech_class = path + '\\\\tech'\n",
    "tech_class_text_files =  glob.glob(f\"{tech_class}\\\\*.txt\")\n",
    "\n",
    "# tech_class_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58eb98f-4959-4c0e-be62-239c9d123c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "article =[]\n",
    "target = []\n",
    "def text_list(file_path_list,class_name):\n",
    "    for file in file_path_list:\n",
    "        with open(file,'r') as f:\n",
    "            text = f.read()\n",
    "            clean_text = re.sub('\\n',' ',text)\n",
    "            article.append(clean_text)\n",
    "            target.append(class_name)\n",
    "text_list(business_class_text_files,'business')\n",
    "text_list(entertainment_class_text_files,'entertainment')\n",
    "text_list(politics_class_text_files,'politics')\n",
    "text_list(sport_class_text_files,'sport')\n",
    "text_list(tech_class_text_files,'tech')\n",
    "print(len(article))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66816aab-e9ed-462c-b798-92da2b8ae519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit  Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.  Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.  Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.  TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake. \n"
     ]
    }
   ],
   "source": [
    "print(article[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d6b1c9-d9fe-4fc4-b53d-afa596c27aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams  BT is introd...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers  Computer user...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code  A new European direct...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns  The man makin...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming  Online role ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     class\n",
       "0     Ad sales boost Time Warner profit  Quarterly p...  business\n",
       "1     Dollar gains on Greenspan speech  The dollar h...  business\n",
       "2     Yukos unit buyer faces loan claim  The owners ...  business\n",
       "3     High fuel prices hit BA's profits  British Air...  business\n",
       "4     Pernod takeover talk lifts Domecq  Shares in U...  business\n",
       "...                                                 ...       ...\n",
       "2220  BT program to beat dialler scams  BT is introd...      tech\n",
       "2221  Spam e-mails tempt net shoppers  Computer user...      tech\n",
       "2222  Be careful how you code  A new European direct...      tech\n",
       "2223  US cyber security chief resigns  The man makin...      tech\n",
       "2224  Losing yourself in online gaming  Online role ...      tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d1 = {'text':article,'class':target}\n",
    "df = pd.DataFrame(d1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be72ccbd-f39f-42b5-8b27-f698060dded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5354d4ed-c698-4f24-aaae-f52b582101ec",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ffd074f-be8b-4e8a-8fbe-eeff5f4f82f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab18f7b5-ed10-4ecc-aa99-ec3549ed9567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f172a44-2f49-433b-990d-c89c33e1f7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            22.966292\n",
       "business         22.921348\n",
       "politics         18.741573\n",
       "tech             18.022472\n",
       "entertainment    17.348315\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()/len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36bc6733-d3e3-4b57-92ea-541df4220152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2225 non-null   object\n",
      " 1   class   2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338bc9d6-192d-4855-bbf7-e596711e6b9c",
   "metadata": {},
   "source": [
    "### Feature Engg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79f02a5-7441-4e14-9650-cf5679b1808f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams  BT is introd...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers  Computer user...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code  A new European direct...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns  The man makin...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming  Online role ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class\n",
       "0     Ad sales boost Time Warner profit  Quarterly p...      0\n",
       "1     Dollar gains on Greenspan speech  The dollar h...      0\n",
       "2     Yukos unit buyer faces loan claim  The owners ...      0\n",
       "3     High fuel prices hit BA's profits  British Air...      0\n",
       "4     Pernod takeover talk lifts Domecq  Shares in U...      0\n",
       "...                                                 ...    ...\n",
       "2220  BT program to beat dialler scams  BT is introd...      4\n",
       "2221  Spam e-mails tempt net shoppers  Computer user...      4\n",
       "2222  Be careful how you code  A new European direct...      4\n",
       "2223  US cyber security chief resigns  The man makin...      4\n",
       "2224  Losing yourself in online gaming  Online role ...      4\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['class'] = encoder.fit_transform(df['class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d84424a-f354-4ec8-ab13-4fcf67525af0",
   "metadata": {},
   "source": [
    "### Word Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83a8a3-85d7-44a5-b91b-b6d5cc6909b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. count vect\n",
    "2. tfidf\n",
    "3. glove\n",
    "4. word2vec\n",
    "5. doc2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e43d6c6-3f4a-4572-aa05-83fa69dffb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1668, 29421) (557, 29421) (1668,) (557,)\n",
      "(1668, 708) (557, 708) (1668,) (557,)\n",
      "(1668, 288) (557, 288) (1668,) (557,)\n"
     ]
    }
   ],
   "source": [
    "x = df['text']\n",
    "y = df['class']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "############### Word embedding for count vec\n",
    "count_vec = CountVectorizer(analyzer=\"word\")\n",
    "count_vec_x = count_vec.fit_transform(x)\n",
    "cv_x_train, cv_x_test, cv_y_train,cv_y_test = train_test_split(count_vec_x,y,random_state=30, test_size=0.25, stratify=y)\n",
    "print(cv_x_train.shape,cv_x_test.shape,cv_y_train.shape,cv_y_test.shape)\n",
    "\n",
    "############### Word embedding for tfidf vec\n",
    "tfidf_vec = TfidfVectorizer(analyzer='word', min_df=0.05)\n",
    "tfidf_vec_x = tfidf_vec.fit_transform(x)\n",
    "tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test = train_test_split(tfidf_vec_x,y,random_state=30, test_size=0.25, stratify=y)\n",
    "print(tfidf_x_train.shape, tfidf_x_test.shape, tfidf_y_train.shape,tfidf_y_test.shape)\n",
    "\n",
    "############### Word embedding for tfidf ngram vec\n",
    "tfidf_ngram_vec = TfidfVectorizer(analyzer='word', ngram_range=(2,3),   min_df=0.05)\n",
    "tfidf_ngram_vec_x = tfidf_ngram_vec.fit_transform(x)\n",
    "tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test = train_test_split(tfidf_ngram_vec_x,y,random_state=30, test_size=0.25, stratify=y)\n",
    "print(tfngram_x_train.shape, tfngram_x_test.shape, tfngram_y_train.shape,tfngram_y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228c319-6a37-4244-8c29-ff7a9d337a97",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2ec75e-969f-4286-9bcc-fc09af6cfba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "\n",
    "def train_model(model_name, x_train,x_test,y_train,y_test):\n",
    "    \"\"\"This function is for model trainingn\"\"\"    \n",
    "    model_name.fit(x_train,y_train)   ### Model Training\n",
    "    prediction = model_name.predict(x_test)\n",
    "    \n",
    "    ############### model evaluation \n",
    "    \n",
    "    ########### Test Data Evaluation \n",
    "    print('#'*50)\n",
    "    print(f\"TESTING DATA EVALUATION\")\n",
    "    acc_score = accuracy_score(y_test,prediction)\n",
    "    cnf_matrix = confusion_matrix(y_test,prediction)\n",
    "    clf_report = classification_report(y_test,prediction)\n",
    "    \n",
    "    print(f\"Accuracy_Score = {acc_score}\")\n",
    "    print(f\"Confusion Matrix = \\n{cnf_matrix}\")\n",
    "    print(f\"Classification Report = \\n{clf_report}\")\n",
    "    \n",
    "    print('#'*50)\n",
    "    print(f\"TRAINING DATA EVALUATION\")\n",
    "    print()\n",
    "    print()\n",
    "    ########### training Data Evaluation \n",
    "    pred = model_name.predict(x_train)\n",
    "    acc_score = accuracy_score(y_train,pred)\n",
    "    cnf_matrix = confusion_matrix(y_train,pred)\n",
    "    clf_report = classification_report(y_train,pred)\n",
    "    \n",
    "    print(f\"Accuracy_Score = {acc_score}\")\n",
    "    print(f\"Confusion Matrix = \\n{cnf_matrix}\")\n",
    "    print(f\"Classification Report = \\n{clf_report}\")\n",
    "    \n",
    "    return \"Success\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8576b66f-2745-488c-8506-b767175474b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9766606822262118\n",
      "Confusion Matrix = \n",
      "[[122   0   3   0   3]\n",
      " [  0  92   1   0   4]\n",
      " [  0   0 104   0   0]\n",
      " [  0   0   1 127   0]\n",
      " [  1   0   0   0  99]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       128\n",
      "           1       1.00      0.95      0.97        97\n",
      "           2       0.95      1.00      0.98       104\n",
      "           3       1.00      0.99      1.00       128\n",
      "           4       0.93      0.99      0.96       100\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.98      0.98      0.98       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9922062350119905\n",
      "Confusion Matrix = \n",
      "[[376   0   3   0   3]\n",
      " [  0 287   0   0   2]\n",
      " [  0   0 311   0   2]\n",
      " [  1   0   0 382   0]\n",
      " [  0   2   0   0 299]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       382\n",
      "           1       0.99      0.99      0.99       289\n",
      "           2       0.99      0.99      0.99       313\n",
      "           3       1.00      1.00      1.00       383\n",
      "           4       0.98      0.99      0.99       301\n",
      "\n",
      "    accuracy                           0.99      1668\n",
      "   macro avg       0.99      0.99      0.99      1668\n",
      "weighted avg       0.99      0.99      0.99      1668\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9443447037701975\n",
      "Confusion Matrix = \n",
      "[[122   0   4   0   2]\n",
      " [  1  90   2   2   2]\n",
      " [  2   1  99   0   2]\n",
      " [  0   3   0 124   1]\n",
      " [  4   5   0   0  91]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       128\n",
      "           1       0.91      0.93      0.92        97\n",
      "           2       0.94      0.95      0.95       104\n",
      "           3       0.98      0.97      0.98       128\n",
      "           4       0.93      0.91      0.92       100\n",
      "\n",
      "    accuracy                           0.94       557\n",
      "   macro avg       0.94      0.94      0.94       557\n",
      "weighted avg       0.94      0.94      0.94       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9580335731414868\n",
      "Confusion Matrix = \n",
      "[[369   1   6   0   6]\n",
      " [  6 268   4   2   9]\n",
      " [ 11   1 297   1   3]\n",
      " [  1   3   2 377   0]\n",
      " [  6   5   1   2 287]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       382\n",
      "           1       0.96      0.93      0.95       289\n",
      "           2       0.96      0.95      0.95       313\n",
      "           3       0.99      0.98      0.99       383\n",
      "           4       0.94      0.95      0.95       301\n",
      "\n",
      "    accuracy                           0.96      1668\n",
      "   macro avg       0.96      0.96      0.96      1668\n",
      "weighted avg       0.96      0.96      0.96      1668\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.7827648114901257\n",
      "Confusion Matrix = \n",
      "[[111   2   5   1   9]\n",
      " [ 18  50   3  18   8]\n",
      " [  9   1  86   2   6]\n",
      " [  7   3   2 114   2]\n",
      " [ 16   6   0   3  75]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       128\n",
      "           1       0.81      0.52      0.63        97\n",
      "           2       0.90      0.83      0.86       104\n",
      "           3       0.83      0.89      0.86       128\n",
      "           4       0.75      0.75      0.75       100\n",
      "\n",
      "    accuracy                           0.78       557\n",
      "   macro avg       0.79      0.77      0.77       557\n",
      "weighted avg       0.79      0.78      0.78       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.8165467625899281\n",
      "Confusion Matrix = \n",
      "[[349   7  10   5  11]\n",
      " [ 40 178  15  43  13]\n",
      " [ 17   7 257  19  13]\n",
      " [  4  13   7 355   4]\n",
      " [ 54  11   5   8 223]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.83       382\n",
      "           1       0.82      0.62      0.70       289\n",
      "           2       0.87      0.82      0.85       313\n",
      "           3       0.83      0.93      0.87       383\n",
      "           4       0.84      0.74      0.79       301\n",
      "\n",
      "    accuracy                           0.82      1668\n",
      "   macro avg       0.82      0.80      0.81      1668\n",
      "weighted avg       0.82      0.82      0.81      1668\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "train_model(nb_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(nb_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(nb_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6bae92a-284e-4a51-b310-1b5788d5c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9712746858168761\n",
      "Confusion Matrix = \n",
      "[[123   1   3   0   1]\n",
      " [  0  94   1   1   1]\n",
      " [  1   1  99   2   1]\n",
      " [  0   1   0 127   0]\n",
      " [  1   1   0   0  98]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       128\n",
      "           1       0.96      0.97      0.96        97\n",
      "           2       0.96      0.95      0.96       104\n",
      "           3       0.98      0.99      0.98       128\n",
      "           4       0.97      0.98      0.98       100\n",
      "\n",
      "    accuracy                           0.97       557\n",
      "   macro avg       0.97      0.97      0.97       557\n",
      "weighted avg       0.97      0.97      0.97       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[382   0   0   0   0]\n",
      " [  0 289   0   0   0]\n",
      " [  0   0 313   0   0]\n",
      " [  0   0   0 383   0]\n",
      " [  0   0   0   0 301]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       382\n",
      "           1       1.00      1.00      1.00       289\n",
      "           2       1.00      1.00      1.00       313\n",
      "           3       1.00      1.00      1.00       383\n",
      "           4       1.00      1.00      1.00       301\n",
      "\n",
      "    accuracy                           1.00      1668\n",
      "   macro avg       1.00      1.00      1.00      1668\n",
      "weighted avg       1.00      1.00      1.00      1668\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9587073608617595\n",
      "Confusion Matrix = \n",
      "[[121   1   4   0   2]\n",
      " [  0  94   2   1   0]\n",
      " [  1   0 100   1   2]\n",
      " [  1   1   0 125   1]\n",
      " [  4   2   0   0  94]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       128\n",
      "           1       0.96      0.97      0.96        97\n",
      "           2       0.94      0.96      0.95       104\n",
      "           3       0.98      0.98      0.98       128\n",
      "           4       0.95      0.94      0.94       100\n",
      "\n",
      "    accuracy                           0.96       557\n",
      "   macro avg       0.96      0.96      0.96       557\n",
      "weighted avg       0.96      0.96      0.96       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9778177458033573\n",
      "Confusion Matrix = \n",
      "[[372   0   6   0   4]\n",
      " [  4 278   3   0   4]\n",
      " [  3   1 306   1   2]\n",
      " [  0   2   0 381   0]\n",
      " [  2   4   0   1 294]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       382\n",
      "           1       0.98      0.96      0.97       289\n",
      "           2       0.97      0.98      0.97       313\n",
      "           3       0.99      0.99      0.99       383\n",
      "           4       0.97      0.98      0.97       301\n",
      "\n",
      "    accuracy                           0.98      1668\n",
      "   macro avg       0.98      0.98      0.98      1668\n",
      "weighted avg       0.98      0.98      0.98      1668\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.7935368043087971\n",
      "Confusion Matrix = \n",
      "[[109   2   7   0  10]\n",
      " [ 13  58   6  11   9]\n",
      " [  7   1  85   2   9]\n",
      " [  7   8   1 110   2]\n",
      " [ 13   5   0   2  80]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79       128\n",
      "           1       0.78      0.60      0.68        97\n",
      "           2       0.86      0.82      0.84       104\n",
      "           3       0.88      0.86      0.87       128\n",
      "           4       0.73      0.80      0.76       100\n",
      "\n",
      "    accuracy                           0.79       557\n",
      "   macro avg       0.80      0.79      0.79       557\n",
      "weighted avg       0.80      0.79      0.79       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.8872901678657075\n",
      "Confusion Matrix = \n",
      "[[353   8  11   3   7]\n",
      " [ 17 224   8  27  13]\n",
      " [  8   9 274  13   9]\n",
      " [  6  11   3 361   2]\n",
      " [ 19  12   2   0 268]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       382\n",
      "           1       0.85      0.78      0.81       289\n",
      "           2       0.92      0.88      0.90       313\n",
      "           3       0.89      0.94      0.92       383\n",
      "           4       0.90      0.89      0.89       301\n",
      "\n",
      "    accuracy                           0.89      1668\n",
      "   macro avg       0.89      0.88      0.88      1668\n",
      "weighted avg       0.89      0.89      0.89      1668\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter= 500 )\n",
    "\n",
    "train_model(model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b8d054-80de-4dbc-8633-f36260c97eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9587073608617595\n",
      "Confusion Matrix = \n",
      "[[124   0   3   0   1]\n",
      " [  3  90   0   2   2]\n",
      " [  4   0  98   2   0]\n",
      " [  0   0   0 128   0]\n",
      " [  5   0   0   1  94]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       128\n",
      "           1       1.00      0.93      0.96        97\n",
      "           2       0.97      0.94      0.96       104\n",
      "           3       0.96      1.00      0.98       128\n",
      "           4       0.97      0.94      0.95       100\n",
      "\n",
      "    accuracy                           0.96       557\n",
      "   macro avg       0.96      0.96      0.96       557\n",
      "weighted avg       0.96      0.96      0.96       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[382   0   0   0   0]\n",
      " [  0 289   0   0   0]\n",
      " [  0   0 313   0   0]\n",
      " [  0   0   0 383   0]\n",
      " [  0   0   0   0 301]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       382\n",
      "           1       1.00      1.00      1.00       289\n",
      "           2       1.00      1.00      1.00       313\n",
      "           3       1.00      1.00      1.00       383\n",
      "           4       1.00      1.00      1.00       301\n",
      "\n",
      "    accuracy                           1.00      1668\n",
      "   macro avg       1.00      1.00      1.00      1668\n",
      "weighted avg       1.00      1.00      1.00      1668\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9551166965888689\n",
      "Confusion Matrix = \n",
      "[[121   0   5   0   2]\n",
      " [  4  89   1   1   2]\n",
      " [  1   2  98   2   1]\n",
      " [  0   2   0 126   0]\n",
      " [  1   0   0   1  98]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       128\n",
      "           1       0.96      0.92      0.94        97\n",
      "           2       0.94      0.94      0.94       104\n",
      "           3       0.97      0.98      0.98       128\n",
      "           4       0.95      0.98      0.97       100\n",
      "\n",
      "    accuracy                           0.96       557\n",
      "   macro avg       0.95      0.95      0.95       557\n",
      "weighted avg       0.96      0.96      0.95       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[382   0   0   0   0]\n",
      " [  0 289   0   0   0]\n",
      " [  0   0 313   0   0]\n",
      " [  0   0   0 383   0]\n",
      " [  0   0   0   0 301]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       382\n",
      "           1       1.00      1.00      1.00       289\n",
      "           2       1.00      1.00      1.00       313\n",
      "           3       1.00      1.00      1.00       383\n",
      "           4       1.00      1.00      1.00       301\n",
      "\n",
      "    accuracy                           1.00      1668\n",
      "   macro avg       1.00      1.00      1.00      1668\n",
      "weighted avg       1.00      1.00      1.00      1668\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.7935368043087971\n",
      "Confusion Matrix = \n",
      "[[111   2   3   1  11]\n",
      " [ 22  51   4  15   5]\n",
      " [  8   3  88   2   3]\n",
      " [  4   8   0 115   1]\n",
      " [ 17   3   1   2  77]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       128\n",
      "           1       0.76      0.53      0.62        97\n",
      "           2       0.92      0.85      0.88       104\n",
      "           3       0.85      0.90      0.87       128\n",
      "           4       0.79      0.77      0.78       100\n",
      "\n",
      "    accuracy                           0.79       557\n",
      "   macro avg       0.80      0.78      0.78       557\n",
      "weighted avg       0.80      0.79      0.79       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[382   0   0   0   0]\n",
      " [  0 289   0   0   0]\n",
      " [  0   0 313   0   0]\n",
      " [  0   0   0 383   0]\n",
      " [  0   0   0   0 301]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       382\n",
      "           1       1.00      1.00      1.00       289\n",
      "           2       1.00      1.00      1.00       313\n",
      "           3       1.00      1.00      1.00       383\n",
      "           4       1.00      1.00      1.00       301\n",
      "\n",
      "    accuracy                           1.00      1668\n",
      "   macro avg       1.00      1.00      1.00      1668\n",
      "weighted avg       1.00      1.00      1.00      1668\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "train_model(model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cb1e826-a7b0-4fd8-ac1e-65851b2f1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Score = 0.947935368043088\n",
      "Confusion Matrix = \n",
      "[[122   0   3   0   3]\n",
      " [  1  90   1   1   4]\n",
      " [  2   3  94   2   3]\n",
      " [  1   1   0 126   0]\n",
      " [  3   1   0   0  96]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       128\n",
      "           1       0.95      0.93      0.94        97\n",
      "           2       0.96      0.90      0.93       104\n",
      "           3       0.98      0.98      0.98       128\n",
      "           4       0.91      0.96      0.93       100\n",
      "\n",
      "    accuracy                           0.95       557\n",
      "   macro avg       0.95      0.95      0.95       557\n",
      "weighted avg       0.95      0.95      0.95       557\n",
      "\n",
      "Accuracy_Score = 0.9622980251346499\n",
      "Confusion Matrix = \n",
      "[[122   1   4   0   1]\n",
      " [  0  94   2   1   0]\n",
      " [  1   1 101   0   1]\n",
      " [  0   2   1 125   0]\n",
      " [  3   3   0   0  94]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       128\n",
      "           1       0.93      0.97      0.95        97\n",
      "           2       0.94      0.97      0.95       104\n",
      "           3       0.99      0.98      0.98       128\n",
      "           4       0.98      0.94      0.96       100\n",
      "\n",
      "    accuracy                           0.96       557\n",
      "   macro avg       0.96      0.96      0.96       557\n",
      "weighted avg       0.96      0.96      0.96       557\n",
      "\n",
      "Accuracy_Score = 0.8043087971274686\n",
      "Confusion Matrix = \n",
      "[[110   2   8   1   7]\n",
      " [ 12  65   6   9   5]\n",
      " [  7   4  83   3   7]\n",
      " [  4  11   2 110   1]\n",
      " [ 12   6   0   2  80]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       128\n",
      "           1       0.74      0.67      0.70        97\n",
      "           2       0.84      0.80      0.82       104\n",
      "           3       0.88      0.86      0.87       128\n",
      "           4       0.80      0.80      0.80       100\n",
      "\n",
      "    accuracy                           0.80       557\n",
      "   macro avg       0.80      0.80      0.80       557\n",
      "weighted avg       0.81      0.80      0.80       557\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "train_model(model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8fcb0-5de9-497a-b28b-5c5f9e6ba955",
   "metadata": {},
   "source": [
    "#### USER TEST FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35d42ac7-aa43-4bda-87f6-124cd2dc29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9766606822262118\n",
      "Confusion Matrix = \n",
      "[[122   0   3   0   3]\n",
      " [  0  92   1   0   4]\n",
      " [  0   0 104   0   0]\n",
      " [  0   0   1 127   0]\n",
      " [  1   0   0   0  99]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       128\n",
      "           1       1.00      0.95      0.97        97\n",
      "           2       0.95      1.00      0.98       104\n",
      "           3       1.00      0.99      1.00       128\n",
      "           4       0.93      0.99      0.96       100\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.98      0.98      0.98       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9922062350119905\n",
      "Confusion Matrix = \n",
      "[[376   0   3   0   3]\n",
      " [  0 287   0   0   2]\n",
      " [  0   0 311   0   2]\n",
      " [  1   0   0 382   0]\n",
      " [  0   2   0   0 299]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       382\n",
      "           1       0.99      0.99      0.99       289\n",
      "           2       0.99      0.99      0.99       313\n",
      "           3       1.00      1.00      1.00       383\n",
      "           4       0.98      0.99      0.99       301\n",
      "\n",
      "    accuracy                           0.99      1668\n",
      "   macro avg       0.99      0.99      0.99      1668\n",
      "weighted avg       0.99      0.99      0.99      1668\n",
      "\n",
      "Article Category = sport\n"
     ]
    }
   ],
   "source": [
    "train_model(nb_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "\n",
    "article = '''Ishan Kishan and Ruturaj Gaikwad opened for India in all five T20Is against South Africa and they are likely to do the same even against Ireland but despite good success - Ishan scored two fifties and Ruturaj one - both of them won't find a place in the XI when regular captain Rohit Sharma and KL Rahul return to the side. Ruturaj might not even make it to the squad as it will see the return of Virat Kohli and Suryakumar Yadav. Once a feared top three, renowned to win T20 matches at will, Rohit, Rahul and Kohli have rarely played together since last year's T20 World Cup. While Rahul had a good IPL with Lucknow Super Giants, two pillars of India's limited-overs batting unit - Rohit and Kohli had one of their worst seasons.'''\n",
    "text = [\"\".join(article)]\n",
    "user_count_vec = count_vec.transform(text)\n",
    "user_count_vec.shape\n",
    "\n",
    "result = nb_model.predict(user_count_vec)\n",
    "class_list = encoder.classes_\n",
    "print(f\"Article Category = {class_list[result[0]]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f18b0a-4d79-45c3-9eb4-a35ca8e1755c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72bb0b8e-af68-4756-92ae-bbe337e60ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "article= '''Singer Billie Eilish is among the many women in the US who have expressed their angst against the Supreme Court's ruling which will lead many states to ban abortion rights. While Billie said the internet gave more importance to Johnny Depp vs Amber Heard trial instead of the court's ruling, Halle Berry shared her angst over “guns having more rights than women'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d3e7e1-4439-49d6-bf6f-2a2bf39927db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model=nb_model.fit(cv_x_train,cv_y_train)\n",
    "with open (\"model.pkl\",'wb') as file:\n",
    "    pickle.dump(model,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "662499da",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = count_vec_x\n",
    "with open (\"cv.pkl\",'wb') as file:\n",
    "    pickle.dump(count_vector,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20760e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec04501b160b2f1c023a0c328658c9281b4c362c04e2daca7181a08fdf12613c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
